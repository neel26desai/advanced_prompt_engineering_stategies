{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPESDJohiT+yfVh3HfYnY4w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neel26desai/advanced_prompt_engineering_stategies/blob/main/PromptTemplates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29eiRA8CUDfe",
        "outputId": "90b8d591-6304-4838-8b64-8249c3b18665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain)\n",
            "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain_community-0.3.8-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain-community\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.36\n",
            "    Uninstalling SQLAlchemy-2.0.36:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.36\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.19\n",
            "    Uninstalling langchain-core-0.3.19:\n",
            "      Successfully uninstalled langchain-core-0.3.19\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.7\n",
            "    Uninstalling langchain-0.3.7:\n",
            "      Successfully uninstalled langchain-0.3.7\n",
            "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.9 langchain-community-0.3.8 langchain-core-0.3.21 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.3.21)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (0.1.143)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (3.10.11)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.23.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install langchain langchain-community\n",
        "!pip install -qU langchain-openai\n",
        "!pip install langchain-core"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "Qa0HDktdURyE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initializing the LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",api_key=userdata.get('open_ai'))"
      ],
      "metadata": {
        "id": "gbftSN50UZI1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Zero Shot prompting"
      ],
      "metadata": {
        "id": "IasGVdOXUgQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Input Text\n",
        "text_input = \"The movie was an absolute masterpiece, with stunning visuals and an emotional storyline.\"\n",
        "\n",
        "# Failure Demonstration: No label guidance provided\n",
        "print(\"--- Failure Test: Zero-shot classification without label guidance ---\")\n",
        "prompt_failure = f\"Classify the sentiment of the following text: \\n\\n{text_input}\"\n",
        "response_failure = llm.invoke(prompt_failure)\n",
        "print(response_failure.content)\n",
        "\n",
        "# Success Demonstration: Zero-shot classification with label guidance\n",
        "print(\"\\n--- Success Test: Zero-shot classification with label guidance ---\")\n",
        "prompt_success = f\"Classify the sentiment of the following text as Positive, Negative, or Neutral: \\n\\n{text_input}\"\n",
        "response_success = llm.invoke(prompt_success)\n",
        "print(response_success.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIec3G4WUe1v",
        "outputId": "e4e9bf12-a7ab-4be7-b613-edde81e9c614"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Failure Test: Zero-shot classification without label guidance ---\n",
            "The sentiment of the text is positive.\n",
            "\n",
            "--- Success Test: Zero-shot classification with label guidance ---\n",
            "The sentiment of the text is Positive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. One Shot learning"
      ],
      "metadata": {
        "id": "lnrnjvvlZE7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Input Text\n",
        "text_input = \"What is the values aaaaaa\"\n",
        "\n",
        "# One-Shot Learning Strategy for Complex Pattern Generation\n",
        "# Failure Demonstration: Lack of explicit pattern example guidance\n",
        "print(\"--- Failure Test: One-shot learning without example guidance ---\")\n",
        "prompt_failure = f\"{text_input}\"\n",
        "response_failure = llm.invoke(prompt_failure)\n",
        "print(response_failure.content)\n",
        "\n",
        "# Success Demonstration: One-shot learning with explicit example\n",
        "print(\"\\n--- Success Test: One-shot learning with explicit example ---\")\n",
        "prompt_success = f\"{text_input}\\n\\n if bbbbb=(2*2*2*2*2), that is the place at which the letter comes in the alphabet (b comes at 2) multiplied by the place the next letter in the serires comes in the alphabet\"\n",
        "response_success = llm.invoke(prompt_success)\n",
        "print(response_success.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgSNDvZUVZgd",
        "outputId": "cc7b8911-0b58-44c2-e22d-10d6227963b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Failure Test: One-shot learning without example guidance ---\n",
            "There is no specific value associated with the string \"aaaaaa\" as it is simply a series of letters.\n",
            "\n",
            "--- Success Test: One-shot learning with explicit example ---\n",
            "The values for \"aaaaaa\" would be 1*1*1*1*1*1 = 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Few Shot"
      ],
      "metadata": {
        "id": "1b68BIEGcFxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Input Text for Translation\n",
        "text_input = \"The company reported increased revenue in the last quarter due to higher sales.\"\n",
        "\n",
        "# Translation Use Case\n",
        "# Failure Demonstration: Lack of clear instruction\n",
        "print(\"--- Failure Test: Translation without clear instruction ---\")\n",
        "prompt_failure = f\"Translate the following text: \\n\\n{text_input}\"\n",
        "response_failure = llm.invoke(prompt_failure)\n",
        "print(response_failure.content)\n",
        "\n",
        "# Success Demonstration: Few-shot Translation with multiple examples\n",
        "print(\"\\n--- Success Test: Translation with explicit examples ---\")\n",
        "prompt_success = (\n",
        "    \"Translate the following text: \\n\\n Here are some examples to help you:\\n\\n\"\n",
        "    \"Example 1: 'Hello, how are you?' - 'Hallo, wie geht es dir?'\\n\"\n",
        "    \"Example 2: 'The weather is nice today.' - 'Das Wetter ist heute schön.'\\n\"\n",
        "    \"Example 3: 'I need to book a hotel room.' - 'Ich muss ein Hotelzimmer buchen.'\\n\\n\"\n",
        "    f\"Now, translate the following text:\\n\\nText: {text_input}\"\n",
        ")\n",
        "response_success = llm.invoke(prompt_success)\n",
        "print(response_success.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOZA-nk8Y7o8",
        "outputId": "0b06eeea-9ad3-464f-cbaf-5b48a48d331f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Failure Test: Translation without clear instruction ---\n",
            "La empresa reportó un incremento en los ingresos en el último trimestre debido a un aumento en las ventas.\n",
            "\n",
            "--- Success Test: Translation with explicit examples ---\n",
            "Das Unternehmen meldete gestiegene Einnahmen im letzten Quartal aufgrund höherer Verkäufe.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Chain of thought"
      ],
      "metadata": {
        "id": "kYn3frB3dXRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Input Text for Chain-of-Thought Reasoning\n",
        "cot_text_input = \"Alice has 5 apples. She gave 3 apples to Bob and then bought 7 more apples. How many apples does Alice have now?\"\n",
        "print(\"\\n--- Success Test: Chain-of-Thought with explicit reasoning ---\")\n",
        "prompt_success_cot = (\n",
        "    \"You are a math tutor. Please solve the problem step-by-step to reach the answer. Here is the question:\\n\\n\"\n",
        "    f\"{cot_text_input}\\n\\n\"\n",
        ")\n",
        "response_success_cot = llm.invoke(prompt_success_cot)\n",
        "print(response_success_cot.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qKJLJg5b9WZ",
        "outputId": "5c8dd34b-a709-41db-e0af-ec93bf8cb8e1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Success Test: Chain-of-Thought with explicit reasoning ---\n",
            "Step 1: Alice starts with 5 apples.\n",
            "Step 2: Alice gives 3 apples to Bob, so she now has 5 - 3 = 2 apples.\n",
            "Step 3: Alice then buys 7 more apples, so she now has 2 + 7 = 9 apples.\n",
            "\n",
            "Therefore, Alice now has 9 apples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Instrution Following"
      ],
      "metadata": {
        "id": "PMM2_he1djjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "promt=\"Explain how to make pasta.\"\n",
        "print(\"Prompt without instruction following:\")\n",
        "print(promt)\n",
        "response_without_instruction = llm.invoke(promt)\n",
        "print(response_without_instruction.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kv7UpNTdc-N",
        "outputId": "3b36dc59-a232-474a-b2af-cd7772fe8828"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt without instruction following:\n",
            "Explain how to make pasta.\n",
            "1. Start by bringing a large pot of water to a boil. Add a generous amount of salt to the water - about 1 tablespoon per 4 cups of water.\n",
            "\n",
            "2. Once the water is boiling, add the pasta. Make sure to stir the pasta occasionally to prevent it from sticking together.\n",
            "\n",
            "3. Cook the pasta according to the package instructions, usually about 8-12 minutes depending on the type of pasta. Taste a piece of pasta to check for doneness - it should be al dente, meaning it should still have a bite to it.\n",
            "\n",
            "4. Once the pasta is cooked to your liking, drain it in a colander in the sink. Do not rinse the pasta as this will remove the starches that help the sauce adhere to the pasta.\n",
            "\n",
            "5. Transfer the drained pasta back to the pot and add your desired sauce. Toss the pasta and sauce together until the pasta is evenly coated.\n",
            "\n",
            "6. Serve the pasta hot, topped with grated cheese, fresh herbs, or any other desired toppings. Enjoy your homemade pasta!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt with instruction following\")\n",
        "prompt = \"Provide a step-by-step guide to make pasta from scratch. Include specific ingredients, quantities, and timings. Describe each cooking step clearly, such as boiling the water, adding salt, and the duration for cooking the pasta. Also, suggest a simple sauce to pair with the pasta and provide any tips to ensure it turns out well.\"\n",
        "print(prompt)\n",
        "response_with_instruction = llm.invoke(prompt)\n",
        "print(response_with_instruction.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MtzYnVzfjW-",
        "outputId": "25e5c64f-a943-4f0c-b95e-a89b64c5f2b1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt with instruction following\n",
            "Provide a step-by-step guide to make pasta from scratch. Include specific ingredients, quantities, and timings. Describe each cooking step clearly, such as boiling the water, adding salt, and the duration for cooking the pasta. Also, suggest a simple sauce to pair with the pasta and provide any tips to ensure it turns out well.\n",
            "Step-by-step guide to making pasta from scratch:\n",
            "\n",
            "Ingredients:\n",
            "- 2 cups all-purpose flour\n",
            "- 2 large eggs\n",
            "- 1/2 tsp salt\n",
            "- Water (if needed)\n",
            "\n",
            "1. In a large mixing bowl, combine the flour and salt. Create a well in the center of the flour mixture.\n",
            "\n",
            "2. Crack the eggs into the well and beat them slightly with a fork.\n",
            "\n",
            "3. Slowly incorporate the flour into the eggs, mixing well until a dough forms.\n",
            "\n",
            "4. Knead the dough on a floured surface for about 10 minutes, or until it becomes smooth and elastic. If the dough is too dry, you can add a little water to help it come together.\n",
            "\n",
            "5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\n",
            "\n",
            "6. After resting, roll out the dough using a pasta machine or a rolling pin until it reaches your desired thickness.\n",
            "\n",
            "7. Cut the dough into your desired shape using a knife, pasta machine, or a pasta cutter.\n",
            "\n",
            "8. Bring a large pot of water to a boil. Add a generous amount of salt to the water.\n",
            "\n",
            "9. Gently drop the pasta into the boiling water and stir to prevent sticking.\n",
            "\n",
            "10. Cook the pasta for 2-4 minutes, or until al dente.\n",
            "\n",
            "11. Drain the pasta and toss with your favorite sauce. A simple sauce can be made by heating olive oil in a pan, adding minced garlic, red pepper flakes, and chopped fresh tomatoes. Cook until the tomatoes are soft, then toss with the cooked pasta.\n",
            "\n",
            "12. Serve the pasta hot and enjoy!\n",
            "\n",
            "Tips:\n",
            "- Make sure to knead the dough well to develop the gluten and create a smooth texture.\n",
            "- Letting the dough rest allows it to relax and makes it easier to roll out.\n",
            "- Be sure to generously salt the pasta water for flavor.\n",
            "- Cooking the pasta al dente (firm to the bite) will give you the best texture.\n",
            "- Fresh homemade pasta cooks much faster than dried pasta, so keep an eye on it while cooking.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Role Playing"
      ],
      "metadata": {
        "id": "a3o2z97Pgpa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt without role playing\")\n",
        "prompt = \"Give me tips for managing time effectively.\"\n",
        "print(prompt)\n",
        "response_without_roleplay = llm.invoke(prompt)\n",
        "print(response_without_roleplay.content)\n",
        "\n",
        "print(\"Prompt with role playing\")\n",
        "prompt = \"Imagine you are a professional time management coach who works with busy executives. Provide detailed and practical advice on managing time effectively, focusing on prioritization, productivity tools, and maintaining a work-life balance. Give examples of common issues executives face and how to solve them.\"\n",
        "print(prompt)\n",
        "response_with_roleplaying = llm.invoke(prompt)\n",
        "print(response_with_roleplaying.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUz-bmrefwY8",
        "outputId": "e7cce471-5cf0-4c4d-d675-6f1df87d9f0a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt without role playing\n",
            "Give me tips for managing time effectively.\n",
            "1. Set clear goals and prioritize tasks: Identify your top priorities and focus on completing those tasks first. Make a to-do list and rank tasks based on importance and deadlines.\n",
            "\n",
            "2. Use a planner or calendar: Write down your tasks, appointments, and deadlines in a planner or digital calendar to stay organized and on track.\n",
            "\n",
            "3. Break tasks into smaller chunks: Break down large tasks into smaller, more manageable tasks to avoid feeling overwhelmed and to make progress more easily.\n",
            "\n",
            "4. Avoid multitasking: Focus on one task at a time to increase productivity and efficiency. Multitasking can actually decrease productivity and lead to errors.\n",
            "\n",
            "5. Set deadlines and stick to them: Set realistic deadlines for tasks and hold yourself accountable for completing them on time. This can help you stay on track and avoid procrastination.\n",
            "\n",
            "6. Minimize distractions: Identify common distractions and try to eliminate or minimize them while working on tasks. This can include turning off notifications, setting specific work hours, or working in a quiet environment.\n",
            "\n",
            "7. Take breaks: Take short breaks throughout the day to rest and recharge. This can help improve focus and productivity when you return to work.\n",
            "\n",
            "8. Delegate tasks: Don't be afraid to ask for help or delegate tasks to others when needed. This can free up your time to focus on more important tasks.\n",
            "\n",
            "9. Review and adjust: Regularly review your progress and adjust your schedule or priorities as needed. This can help you stay on track and make necessary changes to improve time management.\n",
            "\n",
            "10. Practice self-care: Make time for self-care activities such as exercise, relaxation, and socializing. Taking care of yourself can help improve focus, energy levels, and overall productivity.\n",
            "Prompt with role playing\n",
            "Imagine you are a professional time management coach who works with busy executives. Provide detailed and practical advice on managing time effectively, focusing on prioritization, productivity tools, and maintaining a work-life balance. Give examples of common issues executives face and how to solve them.\n",
            "As a professional time management coach working with busy executives, I understand the challenges that come with juggling multiple responsibilities and priorities. Here are some detailed and practical tips on managing time effectively:\n",
            "\n",
            "1. Prioritization:\n",
            "- Start each day by creating a list of tasks and goals, and prioritize them based on importance and urgency. Use tools like the Eisenhower Matrix to categorize tasks into four quadrants: important and urgent, important but not urgent, urgent but not important, and neither urgent nor important.\n",
            "- Focus on completing high-priority tasks first before moving on to less important ones. Avoid getting distracted by less important tasks that can wait.\n",
            "- Delegate tasks that can be handled by others, freeing up your time to focus on more strategic activities.\n",
            "\n",
            "2. Productivity tools:\n",
            "- Utilize productivity tools such as project management software, task management apps, and calendar tools to help you stay organized and on track. Tools like Trello, Asana, and Google Calendar can help you manage deadlines, track progress, and collaborate with team members effectively.\n",
            "- Use time tracking apps to monitor how you spend your time and identify areas where you can improve efficiency. Tools like RescueTime and Toggl can provide insights into your daily habits and help you make adjustments as needed.\n",
            "\n",
            "3. Maintaining work-life balance:\n",
            "- Set boundaries between work and personal life by establishing specific work hours and sticking to them. Avoid checking work emails or taking calls outside of designated work hours.\n",
            "- Schedule regular breaks throughout the day to recharge and prevent burnout. Taking short breaks to stretch, walk, or meditate can help improve focus and productivity.\n",
            "- Make time for activities outside of work that bring you joy and relaxation, such as exercise, hobbies, or spending time with loved ones. Prioritize self-care to avoid feeling overwhelmed and stressed.\n",
            "\n",
            "Common issues executives face and how to solve them:\n",
            "1. Overcommitting: Executives often struggle with saying no to additional tasks or projects, leading to a packed schedule and increased stress. To address this issue, executives should assess their current workload and prioritize tasks based on importance and impact. Learn to delegate tasks to others and set realistic expectations for what can be accomplished in a given timeframe.\n",
            "\n",
            "2. Lack of focus: With a constant stream of emails, meetings, and interruptions, executives may find it challenging to stay focused on important tasks. To combat this issue, executives should schedule blocks of uninterrupted time for deep work, turn off notifications, and create a distraction-free work environment. Using techniques like the Pomodoro Technique (working in focused intervals with short breaks) can also help improve focus and productivity.\n",
            "\n",
            "3. Work-life imbalance: Executives often struggle to find time for personal activities and self-care, leading to burnout and decreased overall well-being. To address this issue, executives should prioritize self-care activities, set boundaries between work and personal life, and make time for activities that bring joy and relaxation. By taking care of their physical and mental health, executives can improve their overall productivity and performance at work.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Style Transfer"
      ],
      "metadata": {
        "id": "ptcUsvC-hOI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt without style transfer\")\n",
        "prompt = \"Describe a sunset.\"\n",
        "print(prompt)\n",
        "response_without_style_transfer = llm.invoke(prompt)\n",
        "print(response_without_style_transfer.content)\n",
        "\n",
        "print(\"Prompt with Shakespearean style transfer\")\n",
        "prompt = \"Describe a sunset as if it were written by William Shakespeare, using Elizabethan language, metaphor, and the romantic imagery typical of his work. Capture the grandeur and emotion of the moment with a poetic flair.\"\n",
        "print(prompt+'\\n')\n",
        "response_with_shakespeare_style = llm.invoke(prompt)\n",
        "print(response_with_shakespeare_style.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVfLgOVmgtWr",
        "outputId": "5ff295e0-ebc1-4b41-d2c3-b51450b58674"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt without style transfer\n",
            "Describe a sunset.\n",
            "The sky is painted in hues of pink, orange, and purple as the sun dips below the horizon, casting a warm glow over the landscape. The clouds are illuminated in shades of gold and crimson, creating a stunning backdrop for the silhouettes of trees and buildings. The air is still and peaceful, as if the world is holding its breath in awe of the beauty unfolding before it. As the last rays of sunlight fade away, the sky darkens to a deep indigo, dotted with twinkling stars. The sunset is a breathtaking display of nature's artistry, a fleeting moment of pure magic.\n",
            "Prompt with Shakespearean style transfer\n",
            "Describe a sunset as if it were written by William Shakespeare, using Elizabethan language, metaphor, and the romantic imagery typical of his work. Capture the grandeur and emotion of the moment with a poetic flair.\n",
            "\n",
            "Behold, the sun doth descend 'pon yonder horizon, casting its golden rays o'er the land. The sky doth blush with hues of crimson and gold, as if painted by the hand of a master artist. The heavens do weep with joy, as the day doth bid farewell to its beloved sun.\n",
            "\n",
            "The clouds do gather 'round like courtiers at a royal feast, their wispy forms bathed in the dying light. The birds do sing a mournful tune, bidding adieu to the day's warmth and light. The trees do bow their heads in reverence, as the world doth prepare for the night's embrace.\n",
            "\n",
            "Oh, how my heart doth swell with longing at the sight of such beauty! The beauty of the sunset doth rival the fairest maiden, its colors a tapestry of love and longing. I am but a humble servant to its majesty, a mere mortal in the presence of such grandeur.\n",
            "\n",
            "As the sun doth sink below the horizon, I am filled with a bittersweet sorrow. For though the day must end, the memory of its splendor shall forever dwell within my heart. Farewell, sweet sun, farewell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Using Delimiter for context"
      ],
      "metadata": {
        "id": "s9mpn1Pfh09i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt using delimiters to specify context\")\n",
        "prompt = \"List all items mentioned in the following text, delimited by square brackets: [To prepare for the camping trip, you need a tent, sleeping bag, flashlight, extra batteries, and insect repellent.] Provide the list of items separately.\"\n",
        "print(prompt)\n",
        "response_with_delimiters = llm.invoke(prompt)\n",
        "print(response_with_delimiters.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhax7ZA7hNn7",
        "outputId": "bc6d5b0b-0c26-4725-d985-d4725d213625"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt using delimiters to specify context\n",
            "List all items mentioned in the following text, delimited by square brackets: [To prepare for the camping trip, you need a tent, sleeping bag, flashlight, extra batteries, and insect repellent.] Provide the list of items separately.\n",
            "Tent, sleeping bag, flashlight, extra batteries, insect repellent.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Providing Reasoning Steps"
      ],
      "metadata": {
        "id": "xi4pENE2iJlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt without reasoning steps\")\n",
        "prompt = \"Is it better to invest in stocks or real estate?\"\n",
        "print(prompt)\n",
        "response_without_reasoning_steps = llm.invoke(prompt)\n",
        "print(response_without_reasoning_steps.content)\n",
        "\n",
        "print(\"Prompt with reasoning steps provided\")\n",
        "prompt = \"Analyze whether it is better to invest in stocks or real estate. Consider the following reasoning steps: 1) Define risk levels of each option, 2) Compare long-term and short-term returns, 3) Discuss liquidity, 4) Mention diversification, and 5) Provide a conclusion based on this analysis.\"\n",
        "print(prompt)\n",
        "response_with_reasoning_steps = llm.invoke(prompt)\n",
        "print(response_with_reasoning_steps.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U5L34Tghzo7",
        "outputId": "cb917ef6-3900-4f97-a7a0-cf3fb78eebfc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt without reasoning steps\n",
            "Is it better to invest in stocks or real estate?\n",
            "There is no one-size-fits-all answer to this question as it ultimately depends on individual financial goals, risk tolerance, and investment timeline. \n",
            "\n",
            "Stocks can offer higher liquidity, potential for higher returns, and diversification through investing in a variety of companies across different industries. However, they also come with higher volatility and market fluctuations.\n",
            "\n",
            "Real estate, on the other hand, can provide a stable source of passive income through rental properties, potential for appreciation in property value, and tax benefits such as deductions for mortgage interest and depreciation. However, real estate investments require more hands-on management, can be less liquid, and come with expenses such as property taxes, maintenance, and insurance.\n",
            "\n",
            "Ultimately, it may be beneficial to have a diversified investment portfolio that includes both stocks and real estate to mitigate risks and take advantage of the potential benefits of each asset class. It is recommended to consult with a financial advisor to determine the best investment strategy based on individual circumstances.\n",
            "Prompt with reasoning steps provided\n",
            "Analyze whether it is better to invest in stocks or real estate. Consider the following reasoning steps: 1) Define risk levels of each option, 2) Compare long-term and short-term returns, 3) Discuss liquidity, 4) Mention diversification, and 5) Provide a conclusion based on this analysis.\n",
            "1) Risk levels: Stocks are generally considered to be riskier than real estate. The stock market can be volatile, with prices fluctuating based on a variety of factors such as economic conditions, company performance, and market sentiment. Real estate, on the other hand, tends to be more stable and less susceptible to sudden market changes.\n",
            "\n",
            "2) Long-term and short-term returns: Historically, both stocks and real estate have provided good returns over the long term. Stocks have the potential for higher returns, but also come with higher volatility. Real estate tends to provide more stable returns over time, with the added benefit of rental income.\n",
            "\n",
            "3) Liquidity: Stocks are more liquid than real estate, as they can be bought and sold easily on the stock market. Real estate, on the other hand, is a less liquid investment as it can take time to sell a property and convert it into cash.\n",
            "\n",
            "4) Diversification: Both stocks and real estate offer the opportunity for diversification. Investing in a mix of stocks from different industries or regions can help spread risk. Similarly, investing in different types of real estate properties (such as residential, commercial, or industrial) can help diversify a real estate portfolio.\n",
            "\n",
            "5) Conclusion: The decision to invest in stocks or real estate ultimately depends on individual preferences, risk tolerance, and investment goals. Stocks may provide higher returns but come with higher risk and volatility. Real estate offers a more stable investment option with the potential for rental income. Both assets can be used to diversify a portfolio and it may be beneficial to have a mix of both stocks and real estate investments. It is important to carefully consider your own financial situation and investment objectives before making a decision.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. In Context Learning"
      ],
      "metadata": {
        "id": "JfDrMYEZiZ_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt without providing an example for context\")\n",
        "prompt = \"Write a paragraph describing a futuristic city.\"\n",
        "print(prompt)\n",
        "response_without_example = llm.invoke(prompt)\n",
        "print(response_without_example.content)\n",
        "\n",
        "print(\"Prompt with an example for context\")\n",
        "prompt = \"Write a paragraph describing a futuristic city. Here's an example to set the tone: 'In the year 2145, glass skyscrapers touched the clouds, interconnected by glowing skybridges that pulsed with electric blue light. The air was alive with the soft hum of hovercars, while below, people strolled through lush parks interspersed with digital art installations. Robots moved seamlessly among the citizens, helping them with everyday tasks, and the sky was illuminated with floating billboards projecting the latest news in bright, colorful holograms.' Now, create your own description of a futuristic city.\"\n",
        "print(prompt)\n",
        "response_with_example = llm.invoke(prompt)\n",
        "print(response_with_example.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8cFn85iiMwD",
        "outputId": "b318f751-084a-4756-9b3d-1381ef9a6f61"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt without providing an example for context\n",
            "Write a paragraph describing a futuristic city.\n",
            "In the year 2050, the city of New Eden stands as a shining beacon of technological advancement and sustainable living. Skyscrapers stretch towards the sky, their sleek glass facades reflecting the sunlight. Hovercars zip through the air, guided by a network of interconnected sensors and AI systems. Green spaces are abundant, with vertical gardens and rooftop farms providing fresh produce for the city's inhabitants. The streets are clean and bustling with activity, as pedestrians walk alongside robots and drones carrying out various tasks. Smart buildings adjust their energy usage based on real-time data, ensuring maximum efficiency and minimal environmental impact. In New Eden, the future is not just a distant dream, but a vibrant reality that has reshaped the way people live, work, and thrive in a modern urban environment.\n",
            "Prompt with an example for context\n",
            "Write a paragraph describing a futuristic city. Here's an example to set the tone: 'In the year 2145, glass skyscrapers touched the clouds, interconnected by glowing skybridges that pulsed with electric blue light. The air was alive with the soft hum of hovercars, while below, people strolled through lush parks interspersed with digital art installations. Robots moved seamlessly among the citizens, helping them with everyday tasks, and the sky was illuminated with floating billboards projecting the latest news in bright, colorful holograms.' Now, create your own description of a futuristic city.\n",
            "In the year 2200, the city of NeoGenesis rose from the ashes of the old world, a marvel of technology and innovation. Buildings made of self-healing materials shimmered in the sunlight, powered by renewable energy sources that lined the streets. The sound of drones whirring overhead filled the air, delivering packages and monitoring traffic patterns with precision. Citizens traveled on sleek maglev trains that crisscrossed the city, connecting them to every corner of the metropolis in minutes. Virtual reality arcades and holographic entertainment centers dotted the landscape, offering immersive experiences that transported people to other worlds. And at the heart of it all, a sentient AI known as Gaia watched over the city, ensuring harmony and balance in this futuristic utopia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Conditional"
      ],
      "metadata": {
        "id": "PdSK30XMivpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt without conditional instructions\")\n",
        "prompt = \"Write a motivational message.\"\n",
        "print(prompt)\n",
        "response_without_condition = llm.invoke(prompt)\n",
        "print(response_without_condition.content)\n",
        "\n",
        "print(\"Prompt with conditional instructions\")\n",
        "prompt = \"Write a motivational message. If the person is struggling with self-doubt, provide reassurance and encouragement for self-belief. If the person is feeling overwhelmed by work, offer advice for managing stress and finding motivation.\"\n",
        "print(prompt)\n",
        "response_with_condition = llm.invoke(prompt)\n",
        "print(response_with_condition.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IMh__C9igW-",
        "outputId": "4d057491-f77c-463e-c4c9-8513a08e66d7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt without conditional instructions\n",
            "Write a motivational message.\n",
            "You are capable of achieving great things. Believe in yourself and your abilities. Stay focused, work hard, and never give up on your dreams. Remember that challenges are opportunities for growth and success. Keep pushing forward and never stop believing in the power of your potential. You have what it takes to make your goals a reality. Keep striving for greatness and never underestimate your worth. You are unstoppable.\n",
            "Prompt with conditional instructions\n",
            "Write a motivational message. If the person is struggling with self-doubt, provide reassurance and encouragement for self-belief. If the person is feeling overwhelmed by work, offer advice for managing stress and finding motivation.\n",
            "Dear friend,\n",
            "\n",
            "I know that self-doubt can be a heavy burden to carry, but I want you to know that you are capable of achieving great things. Believe in yourself and your abilities, because you have everything it takes to succeed. Remember that everyone faces challenges and setbacks, but it's how we handle them that defines our strength and resilience. Trust in your journey and have faith in your potential.\n",
            "\n",
            "If you're feeling overwhelmed by work, take a moment to breathe and regroup. Break down your tasks into manageable chunks and prioritize what needs to be done first. Remember to take breaks and practice self-care to recharge your energy. Find motivation in the small victories and progress you make each day. You are doing your best, and that is always enough.\n",
            "\n",
            "Keep pushing forward, stay positive, and know that you are capable of overcoming any obstacle that comes your way. Believe in yourself, trust in your abilities, and never underestimate the power of your own potential. You've got this!\n",
            "\n",
            "With love and support,\n",
            "\n",
            "[Your Name]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Translation"
      ],
      "metadata": {
        "id": "MB19abRKi8BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt without additional translation instructions\")\n",
        "prompt = \"Translate this text to Spanish: 'I hope you have a great day.'\"\n",
        "print(prompt)\n",
        "response_without_additional_instructions = llm.invoke(prompt)\n",
        "print(response_without_additional_instructions.content)\n",
        "\n",
        "print(\"Prompt with additional translation instructions\")\n",
        "prompt = \"Translate this text to Spanish: 'I hope you have a great day.' Please make sure the translation is informal and friendly, suitable for a close friend.\"\n",
        "print(prompt)\n",
        "response_with_additional_instructions = llm.invoke(prompt)\n",
        "print(response_with_additional_instructions.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v5lS3uhiy4t",
        "outputId": "dff6e0f7-ab79-40eb-a317-a6232a2a5645"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt without additional translation instructions\n",
            "Translate this text to Spanish: 'I hope you have a great day.'\n",
            "Espero que tengas un gran día.\n",
            "Prompt with additional translation instructions\n",
            "Translate this text to Spanish: 'I hope you have a great day.' Please make sure the translation is informal and friendly, suitable for a close friend.\n",
            "Espero que tengas un día genial.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Multiturn Converation"
      ],
      "metadata": {
        "id": "lw_osRcljOuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"### Multi-Turn Dialogue Example ###\")\n",
        "prompt = \"\"\"You are a helpful assistant conversing with a user. Follow the conversation below:\n",
        "\n",
        "User: \"Hey, can you help me plan a road trip?\"\n",
        "Assistant: \"Of course! I'd love to help. Where are you thinking of going?\"\n",
        "User: \"I was thinking of driving from San Francisco to Los Angeles.\"\n",
        "Assistant: \"That sounds like a fantastic trip! How long do you want to take for the drive, and what are you interested in seeing along the way?\"\n",
        "\n",
        "Now continue the conversation, offering suggestions for scenic stops, timing, and activities along the way.\"\"\"\n",
        "print(prompt)\n",
        "response = llm.invoke(prompt)\n",
        "print(\"Response:\", response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVUu4_Q0i_WQ",
        "outputId": "c91eb771-305d-4a3b-d624-d3005c61f479"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Multi-Turn Dialogue Example ###\n",
            "You are a helpful assistant conversing with a user. Follow the conversation below:\n",
            "\n",
            "User: \"Hey, can you help me plan a road trip?\"\n",
            "Assistant: \"Of course! I'd love to help. Where are you thinking of going?\"\n",
            "User: \"I was thinking of driving from San Francisco to Los Angeles.\"\n",
            "Assistant: \"That sounds like a fantastic trip! How long do you want to take for the drive, and what are you interested in seeing along the way?\"\n",
            "\n",
            "Now continue the conversation, offering suggestions for scenic stops, timing, and activities along the way.\n",
            "Response: User: \"I have about 3 days for the trip. I definitely want to see some beautiful coastal views and maybe some cool small towns along the way.\"\n",
            "Assistant: \"Great! I recommend starting early in the morning to maximize your time on the road. One scenic stop you can't miss is Big Sur, with its stunning cliffs and ocean views. You can also check out Monterey for its historic Cannery Row and the famous Monterey Bay Aquarium. Further south, you can explore the charming town of Cambria and visit Hearst Castle in San Simeon. And of course, don't forget to stop at iconic spots like the Bixby Creek Bridge and McWay Falls in Julia Pfeiffer Burns State Park. These are just a few suggestions, but there are so many hidden gems to discover along the Pacific Coast Highway. Enjoy your trip!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14. Code Generation"
      ],
      "metadata": {
        "id": "xwwnwo9AkfkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt with specific code generation instructions\")\n",
        "prompt = \"Write a Python function named `add_numbers` that takes two integer arguments and returns their sum. Make sure to include proper type hints, a docstring explaining the function, and an example of how to use the function.\"\n",
        "print(prompt)\n",
        "response_with_specific_instructions = llm.invoke(prompt)\n",
        "print(response_with_specific_instructions.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaGT8ZYYjUQr",
        "outputId": "7da03211-6767-4c7e-bcad-51a6e248111c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt with specific code generation instructions\n",
            "Write a Python function named `add_numbers` that takes two integer arguments and returns their sum. Make sure to include proper type hints, a docstring explaining the function, and an example of how to use the function.\n",
            "```python\n",
            "def add_numbers(num1: int, num2: int) -> int:\n",
            "    \"\"\"\n",
            "    This function takes two integer arguments and returns their sum.\n",
            "\n",
            "    Args:\n",
            "    num1 (int): The first integer.\n",
            "    num2 (int): The second integer.\n",
            "\n",
            "    Returns:\n",
            "    int: The sum of the two integers.\n",
            "    \"\"\"\n",
            "    return num1 + num2\n",
            "\n",
            "# Example\n",
            "result = add_numbers(5, 3)\n",
            "print(result)  # Output: 8\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 15. Text Summarization"
      ],
      "metadata": {
        "id": "eNo_hNl2kvm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt with specific summarization instructions\")\n",
        "prompt = \"Summarize the following text in two to three concise sentences, focusing on the main arguments and key details. Avoid including any minor details or examples: 'Artificial Intelligence is transforming various industries, from healthcare to finance. By automating tasks, improving accuracy, and generating new insights, AI is helping businesses make better decisions. However, concerns about job displacement and ethics are also growing as AI technology becomes more advanced.'\"\n",
        "print(prompt)\n",
        "response_with_specific_instructions = llm.invoke(prompt)\n",
        "print('\\n\\n')\n",
        "print(response_with_specific_instructions.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6avjlnzkkiyD",
        "outputId": "72a8af4f-9080-4dfc-f6b6-21da9ef03558"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt with specific summarization instructions\n",
            "Summarize the following text in two to three concise sentences, focusing on the main arguments and key details. Avoid including any minor details or examples: 'Artificial Intelligence is transforming various industries, from healthcare to finance. By automating tasks, improving accuracy, and generating new insights, AI is helping businesses make better decisions. However, concerns about job displacement and ethics are also growing as AI technology becomes more advanced.'\n",
            "\n",
            "\n",
            "\n",
            "Artificial Intelligence is revolutionizing industries by automating tasks, improving accuracy, and providing new insights for decision-making. Despite these benefits, concerns about job loss and ethical implications are increasing as AI technology advances.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 16. Logical Reasoning"
      ],
      "metadata": {
        "id": "_Fs0y8r2lGpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt without detailed reasoning steps\")\n",
        "prompt = \"Determine if the following statement is true or false: 'All squares are rectangles, and all rectangles are quadrilaterals. Therefore, all squares are quadrilaterals.'\"\n",
        "print(prompt)\n",
        "response_without_detailed_reasoning = llm.invoke(prompt)\n",
        "print('\\n\\n')\n",
        "print(response_without_detailed_reasoning.content)\n",
        "\n",
        "print(\"Prompt with detailed reasoning steps\")\n",
        "prompt = \"Determine if the following statement is true or false. Provide a detailed step-by-step explanation of your reasoning, including any assumptions you make and any logical deductions that lead to your conclusion. Statement: 'All squares are rectangles, and all rectangles are quadrilaterals. Therefore, all squares are quadrilaterals.'\"\n",
        "print(prompt)\n",
        "print('\\n\\n')\n",
        "response_with_detailed_reasoning = llm.invoke(prompt)\n",
        "print(response_with_detailed_reasoning.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuv5OC3mk-Ox",
        "outputId": "6e6a629f-079d-4425-afc2-2aa561cf0799"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt without detailed reasoning steps\n",
            "Determine if the following statement is true or false: 'All squares are rectangles, and all rectangles are quadrilaterals. Therefore, all squares are quadrilaterals.'\n",
            "\n",
            "\n",
            "\n",
            "True\n",
            "Prompt with detailed reasoning steps\n",
            "Determine if the following statement is true or false. Provide a detailed step-by-step explanation of your reasoning, including any assumptions you make and any logical deductions that lead to your conclusion. Statement: 'All squares are rectangles, and all rectangles are quadrilaterals. Therefore, all squares are quadrilaterals.'\n",
            "\n",
            "\n",
            "\n",
            "The statement is true.\n",
            "\n",
            "1. All squares are rectangles:\n",
            "- A square is a type of rectangle where all four sides are equal in length and all four angles are right angles. Therefore, all squares can be classified as rectangles, but not all rectangles are squares.\n",
            "\n",
            "2. All rectangles are quadrilaterals:\n",
            "- A rectangle is a type of quadrilateral, which is a polygon with four sides. In a rectangle, opposite sides are parallel and equal in length, and all angles are right angles.\n",
            "\n",
            "3. Combining the two statements:\n",
            "- Since all squares are rectangles and all rectangles are quadrilaterals, it follows that all squares are quadrilaterals. This is because a square fulfills the criteria of being both a rectangle and a quadrilateral.\n",
            "\n",
            "Therefore, the statement \"All squares are rectangles, and all rectangles are quadrilaterals. Therefore, all squares are quadrilaterals\" is true.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 17. Comparision Analysis"
      ],
      "metadata": {
        "id": "srNKf1A_ljzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt without specific comparative analysis instructions\")\n",
        "prompt = \"Compare renewable energy and fossil fuels.\"\n",
        "print(prompt)\n",
        "response_without_specific_instructions = llm.invoke(prompt)\n",
        "print(response_without_specific_instructions.content)\n",
        "\n",
        "print(\"Prompt with specific comparative analysis instructions\")\n",
        "prompt = \"Compare renewable energy and fossil fuels based on the following aspects: cost-effectiveness, environmental impact, availability, and scalability. Provide both the advantages and disadvantages of each type of energy source, and conclude with a recommendation for which energy source is more suitable for a sustainable future.\"\n",
        "print(prompt)\n",
        "print('\\n\\n')\n",
        "response_with_specific_instructions = llm.invoke(prompt)\n",
        "print(response_with_specific_instructions.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGMzjbJ7ldcZ",
        "outputId": "afb98084-654e-4581-ea13-3b30072ee128"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt without specific comparative analysis instructions\n",
            "Compare renewable energy and fossil fuels.\n",
            "Renewable energy sources, such as solar, wind, hydro, and geothermal power, are derived from natural processes that are constantly replenished. These sources are considered sustainable and environmentally friendly because they do not deplete finite resources and produce minimal greenhouse gas emissions. In contrast, fossil fuels, such as coal, oil, and natural gas, are non-renewable resources that are formed over millions of years and are extracted through mining and drilling processes. Fossil fuels are major contributors to air pollution, climate change, and environmental degradation.\n",
            "\n",
            "Renewable energy sources have lower operational costs and are becoming increasingly cost-competitive with fossil fuels. They also have the potential to create new jobs and stimulate economic growth in the renewable energy sector. On the other hand, fossil fuels require significant infrastructure and investment for extraction, transportation, and processing, and their prices are subject to market fluctuations and geopolitical factors.\n",
            "\n",
            "In terms of energy security, renewable energy sources are considered more reliable and decentralized than fossil fuels, which are often controlled by a few large corporations and countries. Additionally, renewable energy technologies have a smaller footprint and can be integrated into existing infrastructure more easily than fossil fuel power plants.\n",
            "\n",
            "Overall, renewable energy is seen as a more sustainable and environmentally friendly alternative to fossil fuels, with the potential to reduce greenhouse gas emissions, mitigate climate change, and promote a cleaner and more resilient energy system.\n",
            "Prompt with specific comparative analysis instructions\n",
            "Compare renewable energy and fossil fuels based on the following aspects: cost-effectiveness, environmental impact, availability, and scalability. Provide both the advantages and disadvantages of each type of energy source, and conclude with a recommendation for which energy source is more suitable for a sustainable future.\n",
            "\n",
            "\n",
            "\n",
            "Cost-effectiveness:\n",
            "- Renewable energy: Advantages include decreasing costs of renewable technologies over time, lower operating costs compared to fossil fuels. Disadvantages include high initial investment costs for infrastructure and intermittency which may require additional storage solutions.\n",
            "- Fossil fuels: Advantages include established infrastructure and relatively low upfront costs. Disadvantages include volatile fuel prices and environmental externalities which can lead to additional costs.\n",
            "\n",
            "Environmental impact:\n",
            "- Renewable energy: Advantages include lower greenhouse gas emissions and less pollution compared to fossil fuels. Disadvantages include land and water usage for large-scale projects and potential impact on local ecosystems.\n",
            "- Fossil fuels: Advantages include energy density and reliability. Disadvantages include greenhouse gas emissions, air pollution, and contribution to climate change.\n",
            "\n",
            "Availability:\n",
            "- Renewable energy: Advantages include abundant sources such as sunlight, wind, and water. Disadvantages include variability in energy production depending on weather conditions.\n",
            "- Fossil fuels: Advantages include established infrastructure and availability in many regions. Disadvantages include finite reserves and potential geopolitical issues related to sourcing.\n",
            "\n",
            "Scalability:\n",
            "- Renewable energy: Advantages include the potential for decentralized energy production and scalability through modular installations. Disadvantages include grid integration challenges and intermittency issues.\n",
            "- Fossil fuels: Advantages include established large-scale infrastructure. Disadvantages include environmental impact and limited scalability in the long term.\n",
            "\n",
            "Recommendation:\n",
            "In conclusion, renewable energy is more suitable for a sustainable future due to its lower environmental impact, decreasing costs, and abundant sources. While fossil fuels may still play a role in the transition to renewable energy, investing in and transitioning towards renewable energy sources is crucial for addressing climate change and ensuring a sustainable energy future.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 18. Name Entity Recognition"
      ],
      "metadata": {
        "id": "LpaK8QrcmAVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt without specific NER instructions\")\n",
        "prompt = \"Identify the named entities in the following text: 'Steve Jobs founded Apple Inc. in Cupertino in 1976.'\"\n",
        "print(prompt)\n",
        "print('\\n\\n')\n",
        "response_without_specific_instructions = llm.invoke(prompt)\n",
        "print(response_without_specific_instructions.content)\n",
        "print('\\n\\n')\n",
        "print(\"Prompt with specific NER instructions\")\n",
        "prompt = \"Identify all named entities in the following text, including people, locations, organizations, and dates. Categorize each entity under its corresponding type: 'Steve Jobs founded Apple Inc. in Cupertino in 1976.'\"\n",
        "print(prompt)\n",
        "print('\\n\\n')\n",
        "response_with_specific_instructions = llm.invoke(prompt)\n",
        "print(response_with_specific_instructions.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcJL_uZmlwBH",
        "outputId": "71b0196f-cebf-40fd-c154-ece47261f94c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt without specific NER instructions\n",
            "Identify the named entities in the following text: 'Steve Jobs founded Apple Inc. in Cupertino in 1976.'\n",
            "\n",
            "\n",
            "\n",
            "Steve Jobs, Apple Inc., Cupertino, 1976\n",
            "\n",
            "\n",
            "\n",
            "Prompt with specific NER instructions\n",
            "Identify all named entities in the following text, including people, locations, organizations, and dates. Categorize each entity under its corresponding type: 'Steve Jobs founded Apple Inc. in Cupertino in 1976.'\n",
            "\n",
            "\n",
            "\n",
            "People:\n",
            "- Steve Jobs\n",
            "\n",
            "Locations:\n",
            "- Cupertino\n",
            "\n",
            "Organizations:\n",
            "- Apple Inc.\n",
            "\n",
            "Dates:\n",
            "- 1976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 19. Text to SQL"
      ],
      "metadata": {
        "id": "JnJ5jWSAmNn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt with specific SQL generation instructions\")\n",
        "prompt = \"Write an SQL query to find all employees from the `employees` table, including their `first_name`, `last_name`, and `hire_date`. Make sure to order the results by `hire_date` in descending order, showing the most recently hired employees first.\"\n",
        "print(prompt)\n",
        "response_with_specific_instructions = llm.invoke(prompt)\n",
        "print(response_with_specific_instructions.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yerKYVdBmGq2",
        "outputId": "129b3711-1c6a-4149-fa24-c704cb5797dc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt with specific SQL generation instructions\n",
            "Write an SQL query to find all employees from the `employees` table, including their `first_name`, `last_name`, and `hire_date`. Make sure to order the results by `hire_date` in descending order, showing the most recently hired employees first.\n",
            "SELECT first_name, last_name, hire_date\n",
            "FROM employees\n",
            "ORDER BY hire_date DESC;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 20. Paraphrasing"
      ],
      "metadata": {
        "id": "SZMgZAB6mddO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt without specific paraphrasing instructions\")\n",
        "prompt = \"Paraphrase the following sentence: 'The project was successful primarily due to the excellent teamwork, effective planning, and dedication of all members involved.'\"\n",
        "print(prompt)\n",
        "response_without_specific_instructions = llm.invoke(prompt)\n",
        "print(response_without_specific_instructions.content)\n",
        "\n",
        "print(\"Prompt with specific paraphrasing instructions\")\n",
        "prompt = \"Paraphrase the following sentence to make it more concise, while retaining the original meaning: 'The project was successful primarily due to the excellent teamwork, effective planning, and dedication of all members involved.'\"\n",
        "print(prompt)\n",
        "response_with_specific_instructions = llm.invoke(prompt)\n",
        "print(response_with_specific_instructions.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O949owERmblb",
        "outputId": "133a0d58-1616-43f0-e819-773357ea629f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt without specific paraphrasing instructions\n",
            "Paraphrase the following sentence: 'The project was successful primarily due to the excellent teamwork, effective planning, and dedication of all members involved.'\n",
            "The success of the project was mainly because of the outstanding collaboration, thorough planning, and commitment of all participants.\n",
            "Prompt with specific paraphrasing instructions\n",
            "Paraphrase the following sentence to make it more concise, while retaining the original meaning: 'The project was successful primarily due to the excellent teamwork, effective planning, and dedication of all members involved.'\n",
            "The project's success was mainly attributed to the strong teamwork, efficient planning, and dedication of all members.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 21. Multiple Choice QA"
      ],
      "metadata": {
        "id": "eajABfl7m_2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prompt without specific instructions for multiple-choice QA\")\n",
        "prompt = \"Answer the following question: What is the capital of France? A) Madrid B) Paris C) Rome D) Berlin\"\n",
        "print(prompt)\n",
        "response_without_specific_instructions = llm.invoke(prompt)\n",
        "print(response_without_specific_instructions.content)\n",
        "\n",
        "print(\"Prompt with specific multiple-choice QA instructions\")\n",
        "prompt = \"Answer the following question based on the given options, and provide a brief explanation of your answer: What is the capital of France? A) Madrid B) Paris C) Rome D) Berlin. Make sure to pick the most accurate choice and explain why it's correct.\"\n",
        "print(prompt)\n",
        "response_with_specific_instructions = llm.invoke(prompt)\n",
        "print(response_with_specific_instructions.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uVj7bmEnAW5",
        "outputId": "6b3ef064-670f-40a9-9f12-a90be9c9fd0c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt without specific instructions for multiple-choice QA\n",
            "Answer the following question: What is the capital of France? A) Madrid B) Paris C) Rome D) Berlin\n",
            "B) Paris\n",
            "Prompt with specific multiple-choice QA instructions\n",
            "Answer the following question based on the given options, and provide a brief explanation of your answer: What is the capital of France? A) Madrid B) Paris C) Rome D) Berlin. Make sure to pick the most accurate choice and explain why it's correct.\n",
            "The correct answer is B) Paris. Paris is the capital city of France. It is known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral. It is also the political, cultural, and economic center of France. Madrid is the capital of Spain, Rome is the capital of Italy, and Berlin is the capital of Germany, so they are not the correct answers for the capital of France.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ii57VVkPm1o2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}